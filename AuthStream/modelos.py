import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression, Ridge, Lasso, LogisticRegression
from sklearn.preprocessing import PolynomialFeatures, StandardScaler
from sklearn.kernel_ridge import KernelRidge
from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, plot_tree
from sklearn.metrics import (r2_score, mean_squared_error, mean_absolute_error, 
                           accuracy_score, precision_score, recall_score, f1_score, 
                           confusion_matrix, roc_curve, auc, classification_report)
import warnings
warnings.filterwarnings('ignore')

def mostrar_modelos_regresion(df):
    """Mostrar interfaz para modelos de regresi√≥n"""
    st.header("üìà Modelos de Regresi√≥n")
    
    if df is None or df.empty:
        st.error("‚ùå No hay datos disponibles para entrenar modelos")
        return
    
    # Seleccionar variables
    columnas_numericas = df.select_dtypes(include=[np.number]).columns.tolist()
    
    if len(columnas_numericas) < 2:
        st.error("‚ùå Se necesitan al menos 2 columnas num√©ricas para regresi√≥n")
        return
    
    col1, col2 = st.columns(2)
    
    with col1:
        variable_objetivo = st.selectbox("üéØ Variable Objetivo (Y)", columnas_numericas)
    
    with col2:
        variables_predictoras = st.multiselect(
            "üìä Variables Predictoras (X)", 
            [col for col in columnas_numericas if col != variable_objetivo]
        )
    
    if not variables_predictoras:
        st.warning("‚ö†Ô∏è Selecciona al menos una variable predictora")
        return
    
    # Preparar datos
    X = df[variables_predictoras]
    y = df[variable_objetivo]
    
    # Divisi√≥n de datos
    test_size = st.slider("üìä Tama√±o del conjunto de prueba (%)", 10, 50, 20) / 100
    random_state = st.number_input("üé≤ Random State", min_value=0, value=42)
    
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=int(random_state)
    )
    
    st.subheader("üîß Configuraci√≥n de Modelos")
    
    # Seleccionar modelos a entrenar
    modelos_seleccionados = st.multiselect(
        "Selecciona los modelos a entrenar:",
        [
            "Regresi√≥n Lineal M√∫ltiple",
            "Regresi√≥n Polin√≥mica",
            "Regresi√≥n con Kernel RBF", 
            "Regresi√≥n con Kernel Polin√≥mico",
            "Regresi√≥n Ridge",
            "Regresi√≥n Lasso"
        ],
        default=["Regresi√≥n Lineal M√∫ltiple"]
    )
    
    if st.button("üöÄ Entrenar Modelos", type="primary"):
        entrenar_modelos_regresion(X_train, X_test, y_train, y_test, modelos_seleccionados, variables_predictoras, variable_objetivo)

def entrenar_modelos_regresion(X_train, X_test, y_train, y_test, modelos_seleccionados, var_predictoras, var_objetivo):
    """Entrenar y evaluar modelos de regresi√≥n"""
    resultados = {}
    
    # Escalar datos para algunos modelos
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    progress_bar = st.progress(0)
    total_modelos = len(modelos_seleccionados)
    
    for i, modelo_nombre in enumerate(modelos_seleccionados):
        st.subheader(f"üîç {modelo_nombre}")
        
        try:
            if modelo_nombre == "Regresi√≥n Lineal M√∫ltiple":
                modelo = LinearRegression()
                modelo.fit(X_train, y_train)
                y_pred = modelo.predict(X_test)
                
                # Mostrar coeficientes
                coef_df = pd.DataFrame({
                    'Variable': var_predictoras,
                    'Coeficiente': modelo.coef_
                })
                st.write("üìä **Coeficientes:**")
                st.dataframe(coef_df, use_container_width=True)
                st.write(f"üéØ **Intercepto:** {modelo.intercept_:.4f}")
            
            elif modelo_nombre == "Regresi√≥n Polin√≥mica":
                grado = st.slider(f"Grado polin√≥mico para {modelo_nombre}", 2, 5, 2, key=f"poly_{i}")
                poly_features = PolynomialFeatures(degree=grado, include_bias=False)
                X_train_poly = poly_features.fit_transform(X_train)
                X_test_poly = poly_features.transform(X_test)
                
                modelo = LinearRegression()
                modelo.fit(X_train_poly, y_train)
                y_pred = modelo.predict(X_test_poly)
                
                st.write(f"üìä **Grado del polinomio:** {grado}")
                st.write(f"üìä **Caracter√≠sticas generadas:** {X_train_poly.shape[1]}")
            
            elif modelo_nombre == "Regresi√≥n con Kernel RBF":
                gamma = st.slider(f"Gamma para RBF", 0.001, 1.0, 0.1, key=f"rbf_{i}")
                modelo = KernelRidge(kernel='rbf', gamma=gamma)
                modelo.fit(X_train_scaled, y_train)
                y_pred = modelo.predict(X_test_scaled)
                
                st.write(f"üìä **Gamma:** {gamma}")
            
            elif modelo_nombre == "Regresi√≥n con Kernel Polin√≥mico":
                grado = st.slider(f"Grado para Kernel Polin√≥mico", 2, 5, 3, key=f"kernel_poly_{i}")
                modelo = KernelRidge(kernel='poly', degree=grado)
                modelo.fit(X_train_scaled, y_train)
                y_pred = modelo.predict(X_test_scaled)
                
                st.write(f"üìä **Grado del kernel:** {grado}")
            
            elif modelo_nombre == "Regresi√≥n Ridge":
                alpha = st.slider(f"Alpha para Ridge", 0.001, 10.0, 1.0, key=f"ridge_{i}")
                modelo = Ridge(alpha=alpha)
                modelo.fit(X_train, y_train)
                y_pred = modelo.predict(X_test)
                
                st.write(f"üìä **Alpha (regularizaci√≥n):** {alpha}")
                
                # Mostrar coeficientes
                coef_df = pd.DataFrame({
                    'Variable': var_predictoras,
                    'Coeficiente': modelo.coef_
                })
                st.write("üìä **Coeficientes regularizados:**")
                st.dataframe(coef_df, use_container_width=True)
            
            elif modelo_nombre == "Regresi√≥n Lasso":
                alpha = st.slider(f"Alpha para Lasso", 0.001, 10.0, 1.0, key=f"lasso_{i}")
                modelo = Lasso(alpha=alpha)
                modelo.fit(X_train, y_train)
                y_pred = modelo.predict(X_test)
                
                st.write(f"üìä **Alpha (regularizaci√≥n):** {alpha}")
                
                # Mostrar coeficientes (algunos pueden ser 0)
                coef_df = pd.DataFrame({
                    'Variable': var_predictoras,
                    'Coeficiente': modelo.coef_
                })
                st.write("üìä **Coeficientes regularizados (Lasso puede hacer algunos = 0):**")
                st.dataframe(coef_df, use_container_width=True)
                
                # Variables seleccionadas por Lasso
                variables_seleccionadas = np.sum(modelo.coef_ != 0)
                st.write(f"üéØ **Variables seleccionadas por Lasso:** {variables_seleccionadas} de {len(var_predictoras)}")
            
            # Calcular m√©tricas
            r2 = r2_score(y_test, y_pred)
            mse = mean_squared_error(y_test, y_pred)
            rmse = np.sqrt(mse)
            mae = mean_absolute_error(y_test, y_pred)
            
            # Mostrar m√©tricas
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("R¬≤", f"{r2:.4f}")
            with col2:
                st.metric("MSE", f"{mse:.4f}")
            with col3:
                st.metric("RMSE", f"{rmse:.4f}")
            with col4:
                st.metric("MAE", f"{mae:.4f}")
            
            # Interpretaci√≥n de R¬≤
            if r2 >= 0.9:
                st.success("‚úÖ Excelente ajuste (R¬≤ ‚â• 0.9)")
            elif r2 >= 0.7:
                st.info("‚úÖ Buen ajuste (R¬≤ ‚â• 0.7)")
            elif r2 >= 0.5:
                st.warning("‚ö†Ô∏è Ajuste moderado (R¬≤ ‚â• 0.5)")
            else:
                st.error("‚ùå Ajuste pobre (R¬≤ < 0.5)")
            
            # Gr√°fico de dispersi√≥n con l√≠nea de regresi√≥n
            fig, ax = plt.subplots(figsize=(10, 6))
            ax.scatter(y_test, y_pred, alpha=0.7)
            ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
            ax.set_xlabel(f'Valores Reales ({var_objetivo})')
            ax.set_ylabel(f'Valores Predichos ({var_objetivo})')
            ax.set_title(f'{modelo_nombre} - Predicciones vs Valores Reales')
            ax.grid(True, alpha=0.3)
            st.pyplot(fig)
            plt.close()
            
            # Guardar resultados
            resultados[modelo_nombre] = {
                'r2': r2,
                'mse': mse, 
                'rmse': rmse,
                'mae': mae,
                'y_test': y_test,
                'y_pred': y_pred
            }
            
        except Exception as e:
            st.error(f"‚ùå Error al entrenar {modelo_nombre}: {str(e)}")
        
        progress_bar.progress((i + 1) / total_modelos)
    
    # Guardar resultados en sesi√≥n
    if 'model_results' not in st.session_state:
        st.session_state.model_results = {}
    st.session_state.model_results['regresion'] = resultados
    
    # Comparaci√≥n de modelos
    if len(resultados) > 1:
        st.subheader("üìä Comparaci√≥n de Modelos")
        comparacion_df = pd.DataFrame({
            'Modelo': list(resultados.keys()),
            'R¬≤': [resultados[m]['r2'] for m in resultados.keys()],
            'RMSE': [resultados[m]['rmse'] for m in resultados.keys()],
            'MAE': [resultados[m]['mae'] for m in resultados.keys()]
        }).sort_values('R¬≤', ascending=False)
        
        st.dataframe(comparacion_df, use_container_width=True)
        
        # Mejor modelo
        mejor_modelo = comparacion_df.iloc[0]['Modelo']
        st.success(f"üèÜ **Mejor modelo:** {mejor_modelo} (R¬≤ = {comparacion_df.iloc[0]['R¬≤']:.4f})")

def mostrar_modelos_logisticos(df):
    """Mostrar interfaz para modelos log√≠sticos"""
    st.header("üìä Modelos Log√≠sticos")
    
    if df is None or df.empty:
        st.error("‚ùå No hay datos disponibles para entrenar modelos")
        return
    
    # Identificar posibles variables categ√≥ricas para clasificaci√≥n
    todas_columnas = df.columns.tolist()
    columnas_numericas = df.select_dtypes(include=[np.number]).columns.tolist()
    
    # Sugerir variables con pocos valores √∫nicos como candidatas para clasificaci√≥n
    candidatas_clasificacion = []
    for col in columnas_numericas:
        valores_unicos = df[col].nunique()
        if valores_unicos <= 10:  # Pocas clases √∫nicas
            candidatas_clasificacion.append(col)
    
    if not candidatas_clasificacion:
        st.warning("‚ö†Ô∏è No se encontraron variables adecuadas para clasificaci√≥n binaria/multiclase.")
        st.info("üí° Creando variable categ√≥rica basada en la mediana para demostraci√≥n...")
        
        # Crear variable categ√≥rica basada en la mediana de una variable num√©rica
        if columnas_numericas:
            var_base = st.selectbox("Selecciona variable para categorizar:", columnas_numericas)
            mediana = df[var_base].median()
            df_modificado = df.copy()
            df_modificado['categoria_target'] = (df_modificado[var_base] > mediana).astype(int)
            candidatas_clasificacion = ['categoria_target']
            df = df_modificado
            st.info(f"‚úÖ Variable 'categoria_target' creada: 1 si {var_base} > {mediana:.2f}, 0 en caso contrario")
    
    # Seleccionar variables
    col1, col2 = st.columns(2)
    
    with col1:
        variable_objetivo = st.selectbox("üéØ Variable Objetivo (Y)", candidatas_clasificacion)
    
    with col2:
        variables_predictoras = st.multiselect(
            "üìä Variables Predictoras (X)", 
            [col for col in columnas_numericas if col != variable_objetivo]
        )
    
    if not variables_predictoras:
        st.warning("‚ö†Ô∏è Selecciona al menos una variable predictora")
        return
    
    # Verificar que la variable objetivo sea binaria o tenga pocas clases
    clases_unicas = df[variable_objetivo].nunique()
    st.info(f"üìä Variable objetivo tiene {clases_unicas} clases √∫nicas")
    
    if clases_unicas > 10:
        st.error("‚ùå La variable objetivo tiene demasiadas clases para regresi√≥n log√≠stica")
        return
    
    # Preparar datos
    X = df[variables_predictoras]
    y = df[variable_objetivo]
    
    # Divisi√≥n de datos
    test_size = st.slider("üìä Tama√±o del conjunto de prueba (%)", 10, 50, 20) / 100
    random_state = st.number_input("üé≤ Random State", min_value=0, value=42, key="logistic_random_state")
    
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=int(random_state), stratify=y
    )
    
    if st.button("üöÄ Entrenar Modelo Log√≠stico", type="primary"):
        entrenar_modelo_logistico(X_train, X_test, y_train, y_test, variables_predictoras, variable_objetivo, df)

def entrenar_modelo_logistico(X_train, X_test, y_train, y_test, var_predictoras, var_objetivo, df_original):
    """Entrenar y evaluar modelo de regresi√≥n log√≠stica"""
    try:
        st.subheader("üîç Regresi√≥n Log√≠stica")
        
        # Escalar datos
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        # Entrenar modelo
        modelo = LogisticRegression(random_state=42, max_iter=1000)
        modelo.fit(X_train_scaled, y_train)
        
        # Predicciones
        y_pred = modelo.predict(X_test_scaled)
        y_pred_proba = modelo.predict_proba(X_test_scaled)
        
        # Mostrar coeficientes y odds ratios
        coef_df = pd.DataFrame({
            'Variable': var_predictoras,
            'Coeficiente': modelo.coef_[0] if len(modelo.coef_.shape) == 2 else modelo.coef_,
            'Odds Ratio': np.exp(modelo.coef_[0] if len(modelo.coef_.shape) == 2 else modelo.coef_)
        })
        st.write("üìä **Coeficientes y Odds Ratios:**")
        st.dataframe(coef_df, use_container_width=True)
        st.write(f"üéØ **Intercepto:** {modelo.intercept_[0]:.4f}")
        
        # Log-odds
        st.subheader("üìà Log-odds y Funci√≥n Sigmoide")
        
        # Graficar funci√≥n sigmoide
        z = np.linspace(-10, 10, 100)
        sigmoid = 1 / (1 + np.exp(-z))
        
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
        
        # Funci√≥n sigmoide
        ax1.plot(z, sigmoid, 'b-', linewidth=2)
        ax1.set_xlabel('Z (log-odds)')
        ax1.set_ylabel('P(Y=1)')
        ax1.set_title('Funci√≥n Sigmoide')
        ax1.grid(True, alpha=0.3)
        ax1.axhline(y=0.5, color='r', linestyle='--', alpha=0.7, label='Umbral = 0.5')
        ax1.axvline(x=0, color='r', linestyle='--', alpha=0.7)
        ax1.legend()
        
        # Distribuci√≥n de probabilidades predichas
        ax2.hist(y_pred_proba[:, 1], bins=20, alpha=0.7, color='skyblue', edgecolor='black')
        ax2.set_xlabel('Probabilidad Predicha')
        ax2.set_ylabel('Frecuencia')
        ax2.set_title('Distribuci√≥n de Probabilidades Predichas')
        ax2.grid(True, alpha=0.3)
        
        st.pyplot(fig)
        plt.close()
        
        # M√©tricas de clasificaci√≥n
        accuracy = accuracy_score(y_test, y_pred)
        precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)
        recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)
        f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)
        
        # Mostrar m√©tricas
        st.subheader("üìä M√©tricas de Clasificaci√≥n")
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("Exactitud", f"{accuracy:.4f}")
        with col2:
            st.metric("Precisi√≥n", f"{precision:.4f}")
        with col3:
            st.metric("Recall", f"{recall:.4f}")
        with col4:
            st.metric("F1-Score", f"{f1:.4f}")
        
        # Interpretaci√≥n de m√©tricas
        if accuracy >= 0.9:
            st.success("‚úÖ Excelente rendimiento (Exactitud ‚â• 90%)")
        elif accuracy >= 0.8:
            st.info("‚úÖ Buen rendimiento (Exactitud ‚â• 80%)")
        elif accuracy >= 0.7:
            st.warning("‚ö†Ô∏è Rendimiento moderado (Exactitud ‚â• 70%)")
        else:
            st.error("‚ùå Rendimiento pobre (Exactitud < 70%)")
        
        # Matriz de confusi√≥n
        st.subheader("üé≠ Matriz de Confusi√≥n")
        cm = confusion_matrix(y_test, y_pred)
        
        fig, ax = plt.subplots(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)
        ax.set_xlabel('Predicci√≥n')
        ax.set_ylabel('Real')
        ax.set_title('Matriz de Confusi√≥n')
        st.pyplot(fig)
        plt.close()
        
        # Curva ROC (solo para clasificaci√≥n binaria)
        clases_unicas = len(np.unique(y_test))
        if clases_unicas == 2:
            st.subheader("üìà Curva ROC")
            
            fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba[:, 1])
            roc_auc = auc(fpr, tpr)
            
            fig, ax = plt.subplots(figsize=(8, 6))
            ax.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')
            ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='L√≠nea base (AUC = 0.5)')
            ax.set_xlim([0.0, 1.0])
            ax.set_ylim([0.0, 1.05])
            ax.set_xlabel('Tasa de Falsos Positivos')
            ax.set_ylabel('Tasa de Verdaderos Positivos')
            ax.set_title('Curva ROC')
            ax.legend(loc="lower right")
            ax.grid(True, alpha=0.3)
            st.pyplot(fig)
            plt.close()
            
            # Interpretaci√≥n del AUC
            if roc_auc >= 0.9:
                st.success(f"‚úÖ Excelente capacidad discriminatoria (AUC = {roc_auc:.4f})")
            elif roc_auc >= 0.8:
                st.info(f"‚úÖ Buena capacidad discriminatoria (AUC = {roc_auc:.4f})")
            elif roc_auc >= 0.7:
                st.warning(f"‚ö†Ô∏è Capacidad discriminatoria moderada (AUC = {roc_auc:.4f})")
            else:
                st.error(f"‚ùå Pobre capacidad discriminatoria (AUC = {roc_auc:.4f})")
            
            # Guardar resultados
            if 'model_results' not in st.session_state:
                st.session_state.model_results = {}
            st.session_state.model_results['logistica'] = {
                'accuracy': accuracy,
                'precision': precision,
                'recall': recall,
                'f1_score': f1,
                'auc': roc_auc,
                'confusion_matrix': cm,
                'y_test': y_test,
                'y_pred': y_pred,
                'y_pred_proba': y_pred_proba
            }
        else:
            st.info("üìä Curva ROC disponible solo para clasificaci√≥n binaria")
            
            # Guardar resultados para clasificaci√≥n multiclase
            if 'model_results' not in st.session_state:
                st.session_state.model_results = {}
            st.session_state.model_results['logistica'] = {
                'accuracy': accuracy,
                'precision': precision,
                'recall': recall,
                'f1_score': f1,
                'confusion_matrix': cm,
                'y_test': y_test,
                'y_pred': y_pred
            }
        
        # Reporte de clasificaci√≥n detallado
        st.subheader("üìã Reporte de Clasificaci√≥n Detallado")
        reporte = classification_report(y_test, y_pred, output_dict=True, zero_division=0)
        reporte_df = pd.DataFrame(reporte).transpose()
        st.dataframe(reporte_df, use_container_width=True)
        
    except Exception as e:
        st.error(f"‚ùå Error al entrenar el modelo log√≠stico: {str(e)}")

def mostrar_arboles_decision(df):
    """Mostrar interfaz para √°rboles de decisi√≥n"""
    st.header("üå≥ √Årboles de Decisi√≥n")
    
    if df is None or df.empty:
        st.error("‚ùå No hay datos disponibles para entrenar modelos")
        return
    
    # Seleccionar tipo de √°rbol
    tipo_arbol = st.selectbox(
        "Selecciona el tipo de √°rbol:",
        ["Clasificaci√≥n", "Regresi√≥n"]
    )
    
    # Identificar variables apropiadas seg√∫n el tipo
    todas_columnas = df.columns.tolist()
    columnas_numericas = df.select_dtypes(include=[np.number]).columns.tolist()
    
    if tipo_arbol == "Clasificaci√≥n":
        # Buscar variables categ√≥ricas o con pocos valores √∫nicos
        candidatas_objetivo = []
        for col in columnas_numericas:
            valores_unicos = df[col].nunique()
            if valores_unicos <= 10:
                candidatas_objetivo.append(col)
        
        if not candidatas_objetivo:
            st.warning("‚ö†Ô∏è No se encontraron variables adecuadas para clasificaci√≥n.")
            st.info("üí° Creando variable categ√≥rica basada en la mediana...")
            
            if columnas_numericas:
                var_base = st.selectbox("Selecciona variable para categorizar:", columnas_numericas)
                mediana = df[var_base].median()
                df_modificado = df.copy()
                df_modificado['categoria_target'] = (df_modificado[var_base] > mediana).astype(int)
                candidatas_objetivo = ['categoria_target']
                df = df_modificado
                st.info(f"‚úÖ Variable 'categoria_target' creada: 1 si {var_base} > {mediana:.2f}, 0 en caso contrario")
        
        variable_objetivo = st.selectbox("üéØ Variable Objetivo (Y)", candidatas_objetivo)
    else:
        variable_objetivo = st.selectbox("üéØ Variable Objetivo (Y)", columnas_numericas)
    
    variables_predictoras = st.multiselect(
        "üìä Variables Predictoras (X)", 
        [col for col in columnas_numericas if col != variable_objetivo]
    )
    
    if not variables_predictoras:
        st.warning("‚ö†Ô∏è Selecciona al menos una variable predictora")
        return
    
    # Configuraci√≥n del √°rbol
    st.subheader("‚öôÔ∏è Configuraci√≥n del √Årbol")
    
    col1, col2 = st.columns(2)
    
    with col1:
        max_depth = st.slider("üìè Profundidad m√°xima", 1, 20, 5)
        min_samples_split = st.slider("üîÑ Min. muestras para dividir", 2, 20, 2)
    
    with col2:
        min_samples_leaf = st.slider("üçÉ Min. muestras en hoja", 1, 20, 1)
        test_size = st.slider("üìä Tama√±o del conjunto de prueba (%)", 10, 50, 20) / 100
    
    random_state = st.number_input("üé≤ Random State", min_value=0, value=42, key="tree_random_state")
    
    # Preparar datos
    X = df[variables_predictoras]
    y = df[variable_objetivo]
    
    # Divisi√≥n de datos (80% entrenamiento, 20% prueba)
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=int(random_state)
    )
    
    st.info(f"üìä Divisi√≥n de datos: {len(X_train)} entrenamiento, {len(X_test)} prueba")
    
    if st.button("üöÄ Entrenar √Årbol de Decisi√≥n", type="primary"):
        entrenar_arbol_decision(X_train, X_test, y_train, y_test, variables_predictoras, 
                              variable_objetivo, tipo_arbol, max_depth, min_samples_split, 
                              min_samples_leaf, int(random_state))

def entrenar_arbol_decision(X_train, X_test, y_train, y_test, var_predictoras, var_objetivo, 
                          tipo_arbol, max_depth, min_samples_split, min_samples_leaf, random_state):
    """Entrenar y evaluar √°rbol de decisi√≥n"""
    try:
        st.subheader(f"üå≥ √Årbol de Decisi√≥n - {tipo_arbol}")
        
        # Crear el modelo seg√∫n el tipo
        if tipo_arbol == "Clasificaci√≥n":
            modelo = DecisionTreeClassifier(
                max_depth=max_depth,
                min_samples_split=min_samples_split,
                min_samples_leaf=min_samples_leaf,
                random_state=random_state
            )
        else:
            modelo = DecisionTreeRegressor(
                max_depth=max_depth,
                min_samples_split=min_samples_split,
                min_samples_leaf=min_samples_leaf,
                random_state=random_state
            )
        
        # Entrenar el modelo
        modelo.fit(X_train, y_train)
        y_pred = modelo.predict(X_test)
        
        # Informaci√≥n del √°rbol
        st.subheader("üìä Informaci√≥n del √Årbol")
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("Profundidad Real", modelo.get_depth())
        with col2:
            st.metric("N√∫mero de Hojas", modelo.get_n_leaves())
        with col3:
            st.metric("Nodos Totales", modelo.tree_.node_count)
        with col4:
            st.metric("Caracter√≠sticas Usadas", np.sum(modelo.feature_importances_ > 0))
        
        # Importancia de variables
        st.subheader("üìà Importancia de Variables")
        importancia_df = pd.DataFrame({
            'Variable': var_predictoras,
            'Importancia': modelo.feature_importances_
        }).sort_values('Importancia', ascending=False)
        
        st.dataframe(importancia_df, use_container_width=True)
        
        # Gr√°fico de importancia
        fig, ax = plt.subplots(figsize=(10, 6))
        sns.barplot(data=importancia_df, x='Importancia', y='Variable', ax=ax)
        ax.set_title('Importancia de Variables')
        ax.set_xlabel('Importancia')
        st.pyplot(fig)
        plt.close()
        
        # M√©tricas de evaluaci√≥n
        st.subheader("üìä M√©tricas de Evaluaci√≥n")
        
        if tipo_arbol == "Clasificaci√≥n":
            accuracy = accuracy_score(y_test, y_pred)
            precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)
            recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)
            f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)
            
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("Exactitud", f"{accuracy:.4f}")
            with col2:
                st.metric("Precisi√≥n", f"{precision:.4f}")
            with col3:
                st.metric("Recall", f"{recall:.4f}")
            with col4:
                st.metric("F1-Score", f"{f1:.4f}")
            
            # Matriz de confusi√≥n
            cm = confusion_matrix(y_test, y_pred)
            fig, ax = plt.subplots(figsize=(8, 6))
            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)
            ax.set_xlabel('Predicci√≥n')
            ax.set_ylabel('Real')
            ax.set_title('Matriz de Confusi√≥n')
            st.pyplot(fig)
            plt.close()
            
        else:
            r2 = r2_score(y_test, y_pred)
            mse = mean_squared_error(y_test, y_pred)
            rmse = np.sqrt(mse)
            mae = mean_absolute_error(y_test, y_pred)
            
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("R¬≤", f"{r2:.4f}")
            with col2:
                st.metric("MSE", f"{mse:.4f}")
            with col3:
                st.metric("RMSE", f"{rmse:.4f}")
            with col4:
                st.metric("MAE", f"{mae:.4f}")
            
            # Interpretaci√≥n de R¬≤
            if r2 >= 0.9:
                st.success("‚úÖ Excelente ajuste (R¬≤ ‚â• 0.9)")
            elif r2 >= 0.7:
                st.info("‚úÖ Buen ajuste (R¬≤ ‚â• 0.7)")
            elif r2 >= 0.5:
                st.warning("‚ö†Ô∏è Ajuste moderado (R¬≤ ‚â• 0.5)")
            else:
                st.error("‚ùå Ajuste pobre (R¬≤ < 0.5)")
            
            # Gr√°fico de predicciones vs reales
            fig, ax = plt.subplots(figsize=(10, 6))
            ax.scatter(y_test, y_pred, alpha=0.7)
            ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
            ax.set_xlabel(f'Valores Reales ({var_objetivo})')
            ax.set_ylabel(f'Valores Predichos ({var_objetivo})')
            ax.set_title('Predicciones vs Valores Reales')
            ax.grid(True, alpha=0.3)
            st.pyplot(fig)
            plt.close()
        
        # Visualizaci√≥n del √°rbol
        st.subheader("üå≥ Visualizaci√≥n del √Årbol")
        
        # Ajustar tama√±o de la figura seg√∫n profundidad
        profundidad = modelo.get_depth()
        
        if profundidad <= 3:
            figsize = (15, 10)
            fontsize = 12
        elif profundidad <= 5:
            figsize = (20, 12)
            fontsize = 10
        elif profundidad <= 8:
            figsize = (25, 15)
            fontsize = 8
            st.info("üå≥ El √°rbol es profundo. La visualizaci√≥n puede ser dif√≠cil de leer. Usa zoom para ver detalles.")
        else:
            figsize = (30, 20)
            fontsize = 6
            st.warning("‚ö†Ô∏è El √°rbol es muy profundo. La visualizaci√≥n puede ser muy grande. Considera reducir la profundidad m√°xima.")
        
        fig, ax = plt.subplots(figsize=figsize)
        plot_tree(modelo, 
                 feature_names=var_predictoras,
                 filled=True, 
                 rounded=True,
                 fontsize=fontsize,
                 ax=ax)
        ax.set_title(f'√Årbol de Decisi√≥n - {tipo_arbol}', fontsize=16, fontweight='bold')
        st.pyplot(fig)
        plt.close()
        
        # Ganancia de informaci√≥n / Criterio de divisi√≥n
        if hasattr(modelo, 'tree_'):
            st.subheader("üìä Informaci√≥n del Criterio de Divisi√≥n")
            if tipo_arbol == "Clasificaci√≥n":
                criterio = "Gini" if modelo.criterion == 'gini' else "Entrop√≠a"
                st.write(f"**Criterio utilizado:** {criterio}")
                
                # Calcular ganancia de informaci√≥n en el nodo ra√≠z
                if len(np.unique(y_train)) > 1:
                    impureza_inicial = modelo.tree_.impurity[0]
                    st.write(f"**Impureza inicial (nodo ra√≠z):** {impureza_inicial:.4f}")
            else:
                st.write(f"**Criterio utilizado:** MSE (Error Cuadr√°tico Medio)")
                impureza_inicial = modelo.tree_.impurity[0]
                st.write(f"**MSE inicial (nodo ra√≠z):** {impureza_inicial:.4f}")
        
        # Guardar resultados
        if 'model_results' not in st.session_state:
            st.session_state.model_results = {}
        
        if tipo_arbol == "Clasificaci√≥n":
            st.session_state.model_results['arbol_clasificacion'] = {
                'accuracy': accuracy,
                'precision': precision,
                'recall': recall,
                'f1_score': f1,
                'depth': modelo.get_depth(),
                'n_leaves': modelo.get_n_leaves(),
                'feature_importances': dict(zip(var_predictoras, modelo.feature_importances_)),
                'y_test': y_test,
                'y_pred': y_pred
            }
        else:
            st.session_state.model_results['arbol_regresion'] = {
                'r2': r2,
                'mse': mse,
                'rmse': rmse,
                'mae': mae,
                'depth': modelo.get_depth(),
                'n_leaves': modelo.get_n_leaves(),
                'feature_importances': dict(zip(var_predictoras, modelo.feature_importances_)),
                'y_test': y_test,
                'y_pred': y_pred
            }
        
    except Exception as e:
        st.error(f"‚ùå Error al entrenar el √°rbol de decisi√≥n: {str(e)}")
